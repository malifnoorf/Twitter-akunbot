{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-shaft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seasonal-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Sastrawi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electric-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 13 10:45:23 2018\n",
    "\n",
    "@author: MSI PANDU\n",
    "DAFTAR API KEY TWITTER DULU\n",
    "consumer_key='p89I417RqcklS0mkAdz8o9lXl'\n",
    "consumer_secret='HApTkG7Ps8Y1lMkijYDBlbsHFh2JEJI4yBTB2uaHVnMwyOJC3a'\n",
    "access_token='837224059-scTPV14pOLRcasGM7tvcD9ZEfZpYlSgCZS9ujvqH'\n",
    "access_token_secret='JpzTZT6nwJWMIgUDCrFfTnpjdbyOTUdBnl5zo4GtAdxdZ'\n",
    "\"\"\"\n",
    "import tweepy\n",
    "import re\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "factory = StopWordRemoverFactory()\n",
    "stopword = factory.create_stop_word_remover()\n",
    "consumer_key='YHrgCwdN231nhgb6uBMQtoujJ'\n",
    "consumer_secret='mG2IfMA7CxUeJ4YYsnfcqhawSyXFGSJQcceKHjZT2xMZBtvV6T'\n",
    "access_token='837224059-IisDL3Oi7byXcWbVgxMQDwL0X4I5ya7RMzrlhGJn'\n",
    "access_token_secret='2Xawaks8HkJvtpWGqPA3dGlYK761uOclZrBerrqvGjwYW'\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "searchQuery = '#covid'\n",
    "retweet_filter='-filter:retweets'\n",
    "\n",
    "\n",
    "data=[]\n",
    "search_results = api.search(q=searchQuery+retweet_filter,lang='id', count=500)\n",
    "for mention in search_results:\n",
    "    tweet =mention.text\n",
    "    tanggal= mention.created_at\n",
    "    retweet=mention.retweet_count\n",
    "    username=mention.author.screen_name\n",
    "    hasil1=re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', tweet)\n",
    "    hasil2= hasil1.encode('ascii', 'ignore').decode('ascii')\n",
    "    hasil3=' '.join(word for word in hasil2.split(' ') if not word.startswith('#'))\n",
    "    hasil4=' '.join(word for word in hasil3.split(' ') if not word.startswith('@'))\n",
    "    katadasar = stemmer.stem(str(hasil4))\n",
    "    stop = stopword.remove(katadasar)\n",
    "    hasil5=(\" \".join(stop.split()))\n",
    "    data.append([hasil5,tanggal,retweet,username])\n",
    "datatw = pd.DataFrame(data)\n",
    "datatw.index.name = 'Index'\n",
    "datatw.to_csv(\"tweetlagii.csv\",header=[\"Tweet\",\"Tanggal\",\"Jumlah Retweet\",\"Username\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arranged-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tanggal</th>\n",
       "      <th>Jumlah Retweet</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kawal yuk teman2 medical beau</td>\n",
       "      <td>2021-03-25 14:42:01</td>\n",
       "      <td>0</td>\n",
       "      <td>drjeffaloys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>update kasus covid-19 indonesia kamis 25 maret...</td>\n",
       "      <td>2021-03-25 14:22:58</td>\n",
       "      <td>1</td>\n",
       "      <td>holopiscom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sobat polri ayo cegah tular covid-19 jaga jara...</td>\n",
       "      <td>2021-03-25 12:53:43</td>\n",
       "      <td>0</td>\n",
       "      <td>PatikrajaPolsek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>negative report mandatory for entering bengalu...</td>\n",
       "      <td>2021-03-25 12:45:47</td>\n",
       "      <td>15</td>\n",
       "      <td>ndtv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>berita 41 kluster institusi didik direkod seja...</td>\n",
       "      <td>2021-03-25 12:43:41</td>\n",
       "      <td>2</td>\n",
       "      <td>bernamadotcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>polri ayo cegah tular covid-19 jaga jarak a</td>\n",
       "      <td>2021-03-25 00:41:45</td>\n",
       "      <td>0</td>\n",
       "      <td>POLSEKBANJARNE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>top news koran rakyat merdeka bule langgar pro...</td>\n",
       "      <td>2021-03-25 00:20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>RakyatMerdeka99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>top news koran rakyat merdeka soal sekolah tat...</td>\n",
       "      <td>2021-03-25 00:10:00</td>\n",
       "      <td>2</td>\n",
       "      <td>RakyatMerdeka99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>update data covid19 sulawesi barat tanggal 24 ...</td>\n",
       "      <td>2021-03-25 00:09:45</td>\n",
       "      <td>1</td>\n",
       "      <td>dinkes_sulbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>taat prokes keren jauh kerumun kurang mobilita...</td>\n",
       "      <td>2021-03-25 00:05:15</td>\n",
       "      <td>0</td>\n",
       "      <td>POLSEK_JTJOGJA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                              Tweet  \\\n",
       "0       0                      kawal yuk teman2 medical beau   \n",
       "1       1  update kasus covid-19 indonesia kamis 25 maret...   \n",
       "2       2  sobat polri ayo cegah tular covid-19 jaga jara...   \n",
       "3       3  negative report mandatory for entering bengalu...   \n",
       "4       4  berita 41 kluster institusi didik direkod seja...   \n",
       "..    ...                                                ...   \n",
       "95     95        polri ayo cegah tular covid-19 jaga jarak a   \n",
       "96     96  top news koran rakyat merdeka bule langgar pro...   \n",
       "97     97  top news koran rakyat merdeka soal sekolah tat...   \n",
       "98     98  update data covid19 sulawesi barat tanggal 24 ...   \n",
       "99     99  taat prokes keren jauh kerumun kurang mobilita...   \n",
       "\n",
       "                Tanggal  Jumlah Retweet         Username  \n",
       "0   2021-03-25 14:42:01               0      drjeffaloys  \n",
       "1   2021-03-25 14:22:58               1       holopiscom  \n",
       "2   2021-03-25 12:53:43               0  PatikrajaPolsek  \n",
       "3   2021-03-25 12:45:47              15             ndtv  \n",
       "4   2021-03-25 12:43:41               2    bernamadotcom  \n",
       "..                  ...             ...              ...  \n",
       "95  2021-03-25 00:41:45               0  POLSEKBANJARNE1  \n",
       "96  2021-03-25 00:20:00               2  RakyatMerdeka99  \n",
       "97  2021-03-25 00:10:00               2  RakyatMerdeka99  \n",
       "98  2021-03-25 00:09:45               1    dinkes_sulbar  \n",
       "99  2021-03-25 00:05:15               0   POLSEK_JTJOGJA  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "unexpected-bottle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         drjeffaloys\n",
       "1          holopiscom\n",
       "2     PatikrajaPolsek\n",
       "3                ndtv\n",
       "4       bernamadotcom\n",
       "           ...       \n",
       "95    POLSEKBANJARNE1\n",
       "96    RakyatMerdeka99\n",
       "97    RakyatMerdeka99\n",
       "98      dinkes_sulbar\n",
       "99     POLSEK_JTJOGJA\n",
       "Name: Username, Length: 100, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "stupid-shanghai",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (1.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from scipy) (1.19.2)\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "conventional-domestic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\coba\\lib\\site-packages (from scipy) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addressed-hampton",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Sentimen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-668ef0d8d650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0msentiment_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentimen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mnumber_of_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentiment_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\coba\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Sentimen'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "tweets = pd.read_csv(\"tweet2.csv\")\n",
    "list(tweets.columns.values)\n",
    "\n",
    "sentiment_counts = tweets.Sentimen.value_counts()\n",
    "number_of_tweets = tweets.Index.count()\n",
    "print(sentiment_counts)\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist(tweets[(tweets.Sentimen == 'negatif')])\n",
    "print(fdist.most_common(50))\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "vectorized_data = count_vectorizer.fit_transform(tweets.Tweet)\n",
    "indexed_data = hstack((np.array(range(0,vectorized_data.shape[0]))[:,None], vectorized_data))\n",
    "\n",
    "\n",
    "\n",
    "def sentiment2target(sentiment):\n",
    "    return {\n",
    "        'salah': 0,\n",
    "        'benar': 1\n",
    "    }[sentiment]\n",
    "\n",
    "targets = tweets.Sentimen.apply(sentiment2target)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "data_train, data_test, targets_train, targets_test = train_test_split(indexed_data, targets, test_size=0.4, random_state=0)\n",
    "data_train_index = data_train[:,0]\n",
    "data_train = data_train[:,1:]\n",
    "data_test_index = data_test[:,0]\n",
    "data_test = data_test[:,1:]\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "kf =  KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "print(\"\\n\\nSVM:\")\n",
    "\n",
    "clf = OneVsRestClassifier(svm.SVC(gamma=0.01, C=100., probability=True, class_weight='balanced', kernel='linear'))\n",
    "cros= cross_val_score(clf, data_train, targets_train, scoring='accuracy', cv = kf)\n",
    "print(cros)\n",
    "print(\"Accuracy: \" , cros.mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-induction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
